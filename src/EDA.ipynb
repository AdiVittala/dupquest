{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import persistence as ps\n",
    "from urllib3.response import HTTPResponse\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import partition_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BUCKET = 'dq-data'\n",
    "HASH_BUCKET = 'dq-hashed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train_set\n",
    "data = 'train.csv'\n",
    "filestream = ps.get_file_stream(bucket=INPUT_BUCKET, filename=data)\n",
    "dtypes = {\n",
    "    'id': 'int64',\n",
    "    'qid1': 'int64',\n",
    "    'qid2': 'int64',\n",
    "    'question1': 'object',\n",
    "    'question2': 'object',\n",
    "    'is_duplicate': 'int64'\n",
    "}\n",
    "df = pd.read_csv(#urlpath=s3_in_url, \n",
    "                                     #storage_options=s3_options,\n",
    "                                     filestream,\n",
    "                                     header=0, \n",
    "                                     usecols=dtypes.keys(), \n",
    "                                     #names=dtypes.keys(),\n",
    "                                     skipinitialspace=True,\n",
    "                                     skip_blank_lines=True,\n",
    "                                     encoding='utf-8')\n",
    "df = df.set_index('id')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 404287 entries, 0 to 404289\n",
      "Data columns (total 5 columns):\n",
      "qid1            404287 non-null int64\n",
      "qid2            404287 non-null int64\n",
      "question1       404287 non-null object\n",
      "question2       404287 non-null object\n",
      "is_duplicate    404287 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#shrink df to 150,000 records\n",
    "df = df.iloc[:75000]\n",
    "\n",
    "X = df.drop(columns=['is_duplicate'])\n",
    "\n",
    "y = df['is_duplicate']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50250 entries, 71916 to 15795\n",
      "Data columns (total 4 columns):\n",
      "qid1         50250 non-null int64\n",
      "qid2         50250 non-null int64\n",
      "question1    50250 non-null object\n",
      "question2    50250 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X,y,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "def get_tokens(process='train'):\n",
    "    if process=='test':\n",
    "        X = X_test\n",
    "    else:\n",
    "        X = X_train\n",
    "    series = pd.Series(pd.concat([X['question1'], X['question2']]),dtype=str)\n",
    "    series.dropna()\n",
    "    for question in series:\n",
    "        yield preprocess_string(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minio.definitions.Object at 0x7f80e7c310b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_file(bucket=INPUT_BUCKET, filename='cc.en.300.bin.gz', filepath='/tmp/cc.en.300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('/tmp/cc.en.300.bin.gz', 'rb') as f_in:\n",
    "    with open('/tmp/cc.en.300.bin', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('/tmp/cc.en.300.bin.gz')\n",
    "from gensim.models import FastText\n",
    "model = FastText.load_fasttext_format('/tmp/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft_vectors(model, process):\n",
    "    for tokens in get_tokens(process):\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                vector = model.wv[token]\n",
    "            except:\n",
    "                continue\n",
    "            vectors.append(vector)\n",
    "        yield np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100500,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ft = np.array([vectors for vectors in get_ft_vectors(model,'train')])\n",
    "X_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1_ft = X_ft[:len(X_train)]\n",
    "X2_ft = X_ft[len(X_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft_test = np.array([vectors for vectors in get_ft_vectors(model,'test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49500,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ft_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1_ft_test = X_ft_test[:len(X_test)]\n",
    "X2_ft_test = X_ft_test[len(X_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X_ft_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_lengths(X):\n",
    "    #q_meta = []\n",
    "    for q in X:\n",
    "        #q_meta.append(len(q))\n",
    "        yield len(q)\n",
    "    #return q_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50250,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_meta_train = [(q1_len, q2_len) for q1_len, q2_len in zip(get_q_lengths(X1_ft), get_q_lengths(X2_ft))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_300 = np.concatenate( \n",
    "    np.vstack( [np.array(np.vsplit(y, y.shape[0])) for y in (x for x in X_ft if x.size>0)] )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482518, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_300.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X1_ft, X2_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "## These are the usual ipython objects, including this one you are creating\n",
    "#ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# Get a sorted list of the objects and their sizes\n",
    "#sorted([(x, sys.getsizeof(globals().get(x))) \n",
    "#        for x in dir() if not x.startswith('_') \n",
    "#        and x not in sys.modules and x not in ipython_vars], \n",
    "#       key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmwrite, mmread\n",
    "mmwrite( 'wor2vec_300_train.mtx', X_train_300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.copy_file(dest_bucket=INPUT_BUCKET, file='wor2vec_300_train.mtx', source='wor2vec_300_train.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X_train_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minio.definitions.Object at 0x7f7ed99c3860>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_file(bucket=INPUT_BUCKET, filename='embed_train.mtx', filepath='embed_train.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "X_rd = mmread('embed_train.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482518, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50250"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild X1_rd and X2_rd\n",
    "X1_list = []\n",
    "X2_list = []\n",
    "#q_halflen = int(len(q_meta_train)/2)\n",
    "#q1_meta = q_meta_train[:q_halflen]\n",
    "#q2_meta = q_meta_train[q_halflen:]\n",
    "q1_ptr = 0\n",
    "for len_q1, _ in q_meta_train:\n",
    "    q1 = np.array(X_rd[q1_ptr:q1_ptr+len_q1])\n",
    "    #q2 = X2_rd_tmp[:len_q2]\n",
    "    X1_list.append(q1)\n",
    "    #X2_list.append(q2)\n",
    "    #X1_rd_tmp = X1_rd_tmp[len_q1:]\n",
    "    #X2_rd_tmp = X2_rd_tmp[len_q2:]\n",
    "    q1_ptr = q1_ptr+len_q1\n",
    "q2_ptr = q1_ptr\n",
    "for _, len_q2 in q_meta_train:\n",
    "    #q1 = X1_rd_tmp[q1_ptr:q1_ptr+len_q1]\n",
    "    q2 = np.array(X_rd[q2_ptr:q2_ptr+len_q2])\n",
    "    #X1_list.append(q1)\n",
    "    X2_list.append(q2)\n",
    "    #X1_rd_tmp = X1_rd_tmp[len_q1:]\n",
    "    #X2_rd_tmp = X2_rd_tmp[len_q2:]\n",
    "    q2_ptr = q2_ptr+len_q2\n",
    "X1_rd = np.array(X1_list)\n",
    "X2_rd = np.array(X2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X1_list, X2_list, X_rd, X1_rd_tmp, X2_rd_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import delayed, compute\n",
    "from dask.distributed import Client\n",
    "from utils import dask\n",
    "client = dask.create_dask_client(num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, polynomial_kernel, sigmoid_kernel, laplacian_kernel, rbf_kernel\n",
    "from scipy.spatial.distance import cdist, directed_hausdorff\n",
    "from scipy.stats import wasserstein_distance\n",
    "from MDAnalysis.analysis.psa import hausdorff, hausdorff_wavg, hausdorff_avg, discrete_frechet\n",
    "def compute_pairwise_kernel(pc1, pc2, method='linear'):\n",
    "    if method=='polynomial':\n",
    "        return polynomial_kernel(pc1, pc2, 2)\n",
    "    elif method=='rbf':\n",
    "        return rbf_kernel(pc1, pc2)\n",
    "    elif method=='sigmoid':\n",
    "        return sigmoid_kernel(pc1, pc2)\n",
    "    elif method=='laplacian':\n",
    "        return laplacian_kernel(pc1, pc2)\n",
    "    else:\n",
    "        return linear_kernel(pc1, pc2)\n",
    "    \n",
    "def compute_pairwise_dist(pc1, pc2, method='euclidean'):\n",
    "    if pc1.size == 0 or pc2.size == 0:\n",
    "        return (np.nan,np.nan,np.nan)\n",
    "    dist_mat = cdist(pc1, pc2, metric=method)\n",
    "    return (np.mean(dist_mat), np.min(dist_mat), np.max(dist_mat))\n",
    "\n",
    "def compute_pairwise_metric(pc1, pc2, method='hausdorff'):\n",
    "    if pc1.size == 0:\n",
    "        return np.nan\n",
    "    if pc2.size == 0:\n",
    "        return np.nan\n",
    "    if method == 'hausdorff':\n",
    "        return directed_hausdorff(pc1, pc2)[0]\n",
    "    if method == 'mda_hausdorff':\n",
    "        return hausdorff(pc1, pc2)\n",
    "    if method == 'mda_hausdorff_wavg':\n",
    "        return hausdorff_wavg(pc1, pc2)\n",
    "    if method == 'mda_hausdorff_avg':\n",
    "        return hausdorff_avg(pc1, pc2)\n",
    "    if method == 'discrete_frechet':\n",
    "        return discrete_frechet(pc1, pc2)\n",
    "        \n",
    "def assign_pwmetric(df, method='euclidean'):\n",
    "    #return compute_pairwise_kernel(pc1_embd, pc2_embd, method=method)\n",
    "    return df.apply(compute_pairwise_dist, method, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#compute_pairwise_metric(np.array([[1,0,0],[1,0,1],[1,1,0]]), np.array([[2,2,2],[1,0,0]]), method='hausdorff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = []\n",
    "chebyshev = []\n",
    "braycurtis = []\n",
    "cosine = []\n",
    "correlation = []\n",
    "hamming = []\n",
    "canberra = []\n",
    "hausdorff = []\n",
    "mda_hausdorff = []\n",
    "mda_hausdorff_wavg = []\n",
    "mda_hausdorff_avg = []\n",
    "discrete_frechet = []\n",
    "#mahalanobis = []\n",
    "#yule = []\n",
    "#dice = []\n",
    "#kulsinski = []\n",
    "#rogerstanimoto = []\n",
    "#russellrao = []\n",
    "#sokalmichener = []\n",
    "for q_tuple in zip(X1_rd, X2_rd):\n",
    "    if q_tuple:\n",
    "        q1_rd, q2_rd = q_tuple\n",
    "        jaccard.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'jaccard'))\n",
    "        chebyshev.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'chebyshev'))\n",
    "        braycurtis.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'braycurtis'))\n",
    "        cosine.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'cosine'))\n",
    "        correlation.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'correlation'))\n",
    "        hamming.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'hamming'))\n",
    "        canberra.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'canberra'))\n",
    "        hausdorff.append(delayed(compute_pairwise_metric)(q1_rd, q2_rd, 'hausdorff'))\n",
    "        mda_hausdorff.append(delayed(compute_pairwise_metric)(q1_rd, q2_rd, 'mda_hausdorff'))\n",
    "        mda_hausdorff_wavg.append(delayed(compute_pairwise_metric)(q1_rd, q2_rd, 'mda_hausdorff_wavg'))\n",
    "        mda_hausdorff_avg.append(delayed(compute_pairwise_metric)(q1_rd, q2_rd, 'mda_hausdorff_avg'))\n",
    "        discrete_frechet.append(delayed(compute_pairwise_metric)(q1_rd, q2_rd, 'discrete_frechet'))\n",
    "        #mahalanobis.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mahalanobis'))\n",
    "        #yule.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'yule'))\n",
    "        #dice.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'dice'))\n",
    "        #kulsinski.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'kulsinski'))\n",
    "        #rogerstanimoto.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'rogerstanimoto'))\n",
    "        #russellrao.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'russellrao'))\n",
    "        #sokalmichener.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'sokalmichener'))\n",
    "    else:\n",
    "        jaccard.append(delayed((np.nan,np.nan,np.nan)))\n",
    "        chebyshev.append(delayed((np.nan,np.nan,np.nan)))\n",
    "        braycurtis.append(delayed((np.nan,np.nan,np.nan))) \n",
    "        cosine.append(delayed((np.nan,np.nan,np.nan)))\n",
    "        correlation.append(delayed((np.nan,np.nan,np.nan)))\n",
    "        hamming.append(delayed((np.nan,np.nan,np.nan))) \n",
    "        canberra.append(delayed((np.nan,np.nan,np.nan)))\n",
    "        hausdorff.append(delayed(np.nan))\n",
    "        mda_hausdorff.append(delayed(np.nan))\n",
    "        mda_hausdorff_wavg.append(delayed(np.nan)) \n",
    "        mda_hausdorff_avg.append(delayed(np.nan))\n",
    "        discrete_frechet.append(delayed(np.nan))\n",
    "        #mahalanobis.append(delayed([]))\n",
    "        #yule.append(delayed([])) \n",
    "        #dice.append(delayed([]))\n",
    "        #kulsinski.append(delayed([]))\n",
    "        #rogerstanimoto.append(delayed([])) \n",
    "        #russellrao.append(delayed([]))\n",
    "        #sokalmichener.append(delayed([])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = compute(*jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev = compute(*chebyshev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "braycurtis = compute(*braycurtis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = compute(*cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = compute(*correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming = compute(*hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canberra = compute(*canberra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hausdorff = compute(*hausdorff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_hausdorff = compute(*mda_hausdorff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_hausdorff_wavg = compute(*mda_hausdorff_wavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_hausdorff_avg = compute(*mda_hausdorff_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_frechet = compute(*discrete_frechet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yule = compute(*yule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dice = compute(*dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kulsinski = compute(*kulsinski)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rogerstanimoto = compute(*rogerstanimoto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#russellrao = compute(*russellrao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sokalmichener = compute(*sokalmichener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(braycurtis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add above metrics to X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train,\n",
    "                     pd.Series((x for x,_,_ in jaccard), name='jaccard_mean',index=X_train.index), \n",
    "                     pd.Series((x for _,x,_ in jaccard), name='jaccard_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in jaccard), name='jaccard_max',index=X_train.index), \n",
    "                     pd.Series((x for x,_,_ in chebyshev), name='chebyshev_mean',index=X_train.index), \n",
    "                     pd.Series((x for _,x,_ in chebyshev), name='chebyshev_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in chebyshev), name='chebyshev_max',index=X_train.index), \n",
    "                     pd.Series((x for x,_,_ in braycurtis), name='braycurtis_mean',index=X_train.index),\n",
    "                     pd.Series((x for _,x,_ in braycurtis), name='braycurtis_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in braycurtis), name='braycurtis_max',index=X_train.index),  \n",
    "                     pd.Series((x for x,_,_ in cosine), name='cosine_mean',index=X_train.index), \n",
    "                     pd.Series((x for _,x,_ in cosine), name='cosine_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in cosine), name='cosine_max',index=X_train.index),  \n",
    "                     pd.Series((x for x,_,_ in correlation), name='correlation_mean',index=X_train.index), \n",
    "                     pd.Series((x for _,x,_ in correlation), name='correlation_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in correlation), name='correlation_max',index=X_train.index),  \n",
    "                     pd.Series((x for x,_,_ in hamming), name='hamming_mean',index=X_train.index), \n",
    "                     pd.Series((x for _,x,_ in hamming), name='hamming_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in hamming), name='hamming_max',index=X_train.index),  \n",
    "                     pd.Series((x for x,_,_ in canberra), name='canberra_mean',index=X_train.index) , \n",
    "                     pd.Series((x for _,x,_ in canberra), name='canberra_min',index=X_train.index), \n",
    "                     pd.Series((x for _,_,x in canberra), name='canberra_max',index=X_train.index),  \n",
    "                     pd.Series(hausdorff, name='hausdorff',index=X_train.index),\n",
    "                     pd.Series(mda_hausdorff, name='mda_hausdorff',index=X_train.index), \n",
    "                     pd.Series(mda_hausdorff_wavg, name='mda_hausdorff_wavg',index=X_train.index), \n",
    "                     pd.Series(mda_hausdorff_avg, name='mda_hausdorff_avg',index=X_train.index) , \n",
    "                     pd.Series(discrete_frechet, name='discrete_frechet',index=X_train.index)\n",
    "                     #pd.Series(yule, name='yule',index=X_train.index), \n",
    "                     #pd.Series(dice, name='dice',index=X_train.index), \n",
    "                     #pd.Series(kulsinski, name='kulsinski',index=X_train.index), \n",
    "                     #pd.Series(rogerstanimoto, name='rogerstanimoto',index=X_train.index), \n",
    "                     #pd.Series(russellrao, name='russellrao',index=X_train.index), \n",
    "                     #pd.Series(sokalmichener, name='sokalmichener',index=X_train.index)\n",
    "                    ], axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_meta_test = [(q1_len, q2_len) for q1_len, q2_len in zip(get_q_lengths(X1_ft_test), get_q_lengths(X2_ft_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_300 = np.concatenate( \n",
    "    np.vstack( [np.array(np.vsplit(y, y.shape[0])) for y in (x for x in X_ft_test if x.size>0)] )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_300.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmwrite, mmread\n",
    "mmwrite( 'wor2vec_300_test.mtx', X_test_300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.copy_file(dest_bucket=INPUT_BUCKET, file='wor2vec_300_test.mtx', source='wor2vec_300_test.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.get_file(bucket=INPUT_BUCKET, filename='embed_test.mtx', filepath='embed_test.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "X_rd_test = mmread('embed_test.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild X1_rd_test and X2_rd_test\n",
    "X1_list = []\n",
    "X2_list = []\n",
    "q1_ptr = 0\n",
    "for len_q1, _ in q_meta_test:\n",
    "    q1 = np.array(X_rd_test[q1_ptr:q1_ptr+len_q1])\n",
    "    X1_list.append(q1)\n",
    "    q1_ptr = q1_ptr+len_q1\n",
    "q2_ptr = q1_ptr\n",
    "for _, len_q2 in q_meta_test:\n",
    "    q2 = np.array(X_rd_test[q2_ptr:q2_ptr+len_q2])\n",
    "    X2_list.append(q2)\n",
    "    q2_ptr = q2_ptr+len_q2\n",
    "X1_rd_test = np.array(X1_list)\n",
    "X2_rd_test = np.array(X2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_rd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X1_list, X2_list, q1_meta, q2_meta, X_rd_test, X1_rd_tmp, X2_rd_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_test = []\n",
    "chebyshev_test = []\n",
    "braycurtis_test = []\n",
    "cosine_test = []\n",
    "correlation_test = []\n",
    "hamming_test = []\n",
    "canberra_test = []\n",
    "hausdorff_test = []\n",
    "mda_hausdorff_test = []\n",
    "mda_hausdorff_wavg_test = []\n",
    "mda_hausdorff_avg_test = []\n",
    "discrete_frechet_test = []\n",
    "#mahalanobis_test = []\n",
    "#yule_test = []\n",
    "#dice_test = []\n",
    "#kulsinski_test = []\n",
    "#rogerstanimoto_test = []\n",
    "#russellrao_test = []\n",
    "#sokalmichener_test = []\n",
    "for q_tuple in zip(X1_rd_test, X2_rd_test):\n",
    "    if q_tuple:\n",
    "        q1_rd, q2_rd = q_tuple\n",
    "        jaccard_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'jaccard'))\n",
    "        chebyshev_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'chebyshev'))\n",
    "        braycurtis_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'braycurtis'))\n",
    "        cosine_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'cosine'))\n",
    "        correlation_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'correlation'))\n",
    "        hamming_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'hamming'))\n",
    "        canberra_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'canberra'))\n",
    "        hausdorff_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'hausdorff'))\n",
    "        mda_hausdorff_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mda_hausdorff'))\n",
    "        mda_hausdorff_wavg_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mda_hausdorff_wavg'))\n",
    "        mda_hausdorff_avg_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mda_hausdorff_avg'))\n",
    "        discrete_frechet_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'discrete_frechet'))\n",
    "        #mahalanobis_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mahalanobis'))\n",
    "        #yule_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'yule'))\n",
    "        #dice_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'dice'))\n",
    "        #kulsinski_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'kulsinski'))\n",
    "        #rogerstanimoto_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'rogerstanimoto'))\n",
    "        #russellrao_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'russellrao'))\n",
    "        #sokalmichener_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'sokalmichener'))\n",
    "    else:\n",
    "        jaccard_test.append(delayed(np.nan))\n",
    "        chebyshev_test.append(delayed(np.nan))\n",
    "        braycurtis_test.append(delayed(np.nan)) \n",
    "        cosine_test.append(delayed(np.nan))\n",
    "        correlation_test.append(delayed(np.nan))\n",
    "        hamming_test.append(delayed(np.nan)) \n",
    "        canberra_test.append(delayed(np.nan))\n",
    "        hausdorff_test.append(delayed(np.nan))\n",
    "        mda_hausdorff_test.append(delayed(np.nan))\n",
    "        mda_hausdorff_wavg_test.append(delayed(np.nan)) \n",
    "        mda_hausdorff_avg_test.append(delayed(np.nan))\n",
    "        discrete_frechet_test.append(delayed(np.nan))\n",
    "        #mahalanobis_test.append(delayed([]))\n",
    "        #yule_test.append(delayed([])) \n",
    "        #dice_test.append(delayed([]))\n",
    "        #kulsinski_test.append(delayed([]))\n",
    "        #rogerstanimoto_test.append(delayed([])) \n",
    "        #russellrao_test.append(delayed([]))\n",
    "        #sokalmichener_test.append(delayed([])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_test = compute(*jaccard_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev_test = compute(*chebyshev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "braycurtis_test = compute(*braycurtis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_test = compute(*cosine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_test = compute(*correlation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_test = compute(*hamming_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canberra_test = compute(*canberra_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hausdorff_test = compute(*hausdorff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_hausdorff_test = compute(*mda_hausdorff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_hausdorff_wavg_test = compute(*mda_hausdorff_wavg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_hausdorff_avg_test = compute(*mda_hausdorff_avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_frechet_test = compute(*discrete_frechet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mahalanobis_test = compute(*mahalanobis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yule_test = compute(*yule_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dice_test = compute(*dice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kulsinski_test = compute(*kulsinski_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rogerstanimoto_test = compute(*rogerstanimoto_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#russellrao_test = compute(*russellrao_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sokalmichener_test = compute(*sokalmichener_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, \n",
    "                     pd.Series(jaccard_test, name='jaccard',index=X_test.index), \n",
    "                     pd.Series(chebyshev_test, name='chebyshev',index=X_test.index), \n",
    "                     pd.Series(braycurtis_test, name='braycurtis',index=X_test.index), \n",
    "                     pd.Series(cosine_test, name='cosine',index=X_test.index), \n",
    "                     pd.Series(correlation_test, name='correlation',index=X_test.index), \n",
    "                     pd.Series(hamming_test, name='hamming',index=X_test.index), \n",
    "                     pd.Series(canberra_test, name='canberra',index=X_test.index),\n",
    "                     pd.Series(hausdorff_test, name='hausdorff',index=X_test.index),\n",
    "                     pd.Series(mda_hausdorff_test, name='mda_hausdorff',index=X_train.index), \n",
    "                     pd.Series(mda_hausdorff_wavg_test, name='mda_hausdorff_wavg',index=X_train.index), \n",
    "                     pd.Series(mda_hausdorff_avg_test, name='mda_hausdorff_avg',index=X_train.index) , \n",
    "                     pd.Series(discrete_frechet_test, name='discrete_frechet',index=X_train.index)\n",
    "                     #pd.Series(yule_test, name='yule',index=X_test.index), \n",
    "                     #pd.Series(dice_test, name='dice',index=X_test.index), \n",
    "                     #pd.Series(kulsinski_test, name='kulsinski',index=X_test.index), \n",
    "                     #pd.Series(rogerstanimoto_test, name='rogerstanimoto',index=X_test.index), \n",
    "                     #pd.Series(russellrao_test, name='russellrao',index=X_test.index), \n",
    "                     #pd.Series(sokalmichener_test, name='sokalmichener',index=X_test.index)\n",
    "                    ], axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pass_through = lambda x:x\n",
    "tfidf = TfidfVectorizer(analyzer=pass_through)\n",
    "X_trfmd = tfidf.fit_transform(get_tokens('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trfmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction using SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import time\n",
    "start = time.time()\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "X_svd = svd.fit_transform(X_trfmd)\n",
    "end =  time.time()\n",
    "print('created SVD transform in time {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1 = X_svd[:len(X_train), :]\n",
    "X2 = X_svd[len(X_train):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_trfmd = tfidf.transform(get_tokens('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_trfmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction using SVD\n",
    "start = time.time()\n",
    "X_test_svd = svd.transform(X_test_trfmd)\n",
    "end =  time.time()\n",
    "print('created SVD transform in time {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1_test = X_test_svd[:len(X_test), :]\n",
    "X2_test = X_test_svd[len(X_test):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build complete feature dataframe\n",
    "X_test_temp = pd.concat([pd.DataFrame(X1_test, columns=['q1_'+str(i) for i in range(X1_test.shape[1])], index=X_test.index), \n",
    "                    pd.DataFrame(X2_test, columns=['q2_'+str(i) for i in range(X2_test.shape[1])], index=X_test.index)], axis=1)\n",
    "X_test_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy-wuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in text size\n",
    "compute_size_diff = lambda row: abs(len(str(row['question1'])) - len(str(row['question2'])))\n",
    "X_train['size_diff'] = X_train.apply(compute_size_diff, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio\n",
    "compute_ratio = lambda row: fuzz.ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['ratio'] = X_train.apply(compute_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial ratio\n",
    "compute_partial_ratio = lambda row: fuzz.partial_ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['partial_ratio'] = X_train.apply(compute_partial_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_sort_ratio\n",
    "compute_token_sort_ratio = lambda row: fuzz.token_sort_ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['token_sort_ratio'] = X_train.apply(compute_token_sort_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_set_ratio\n",
    "compute_token_set_ratio = lambda row: fuzz.token_set_ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['token_set_ratio'] = X_train.apply(compute_token_set_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build complete feature dataframe\n",
    "#X_train_temp = pd.concat([pd.DataFrame(X1, columns=['q1_'+str(i) for i in range(X1.shape[1])], index=X_train.index), \n",
    "#                     pd.DataFrame(X2, columns=['q2_'+str(i) for i in range(X2.shape[1])], index=X_train.index)], axis=1)\n",
    "#X_train_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.concat([X_train_temp, X_train], axis=1)\n",
    "#del X_train_temp\n",
    "X_train_final = X_train.drop(columns=['qid1', 'qid2','question1','question2']).dropna()\n",
    "X_train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in text size\n",
    "X_test['size_diff'] = X_test.apply(compute_size_diff, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio\n",
    "X_test['ratio'] = X_test.apply(compute_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial ratio\n",
    "X_test['partial_ratio'] = X_test.apply(compute_partial_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_sort_ratio\n",
    "X_test['token_sort_ratio'] = X_test.apply(compute_token_sort_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_set_ratio\n",
    "X_test['token_set_ratio'] = X_test.apply(compute_token_set_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = X_test.drop(columns=['question1','question2', 'qid1', 'qid2']).dropna()\n",
    "X_test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "logr_model = LogisticRegression(random_state=42)\n",
    "param_grid = {'C': np.logspace(-2, 7, 10),\n",
    "             #'penalty': ['l1','l2'],\n",
    "             'tol': np.logspace(-5, -1, 5),\n",
    "             #'solver': ['lbfgs']\n",
    "             #'max_iter': np.linspace(10, 1000, 10)\n",
    "             }\n",
    "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
    "y_train_final = y_train.loc[X_train_final.index]\n",
    "logr_cv.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_model = LogisticRegression(#solver=logr_cv.best_params_['solver'], \n",
    "                                random_state=42, \n",
    "                                C=logr_cv.best_params_['C'], \n",
    "                                tol=logr_cv.best_params_['tol'], \n",
    "                                #max_iter=logr_cv.best_params_['max_iter'], \n",
    "                                n_jobs=-1)\n",
    "logr_model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_pred = logr_model.predict(X_test_final)\n",
    "y_test_final = y_test.loc[X_test_final.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "logr_acc_score = accuracy_score(y_test_final, logr_pred)\n",
    "logr_prec_score = precision_score(y_test_final, logr_pred)\n",
    "logr_rec_score = recall_score(y_test_final, logr_pred)\n",
    "print('Logistic Regression')\n",
    "print('accuracy score : {}'.format(logr_acc_score))\n",
    "print('precision score : {}'.format(logr_prec_score))\n",
    "print('recall score : {}'.format(logr_rec_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
