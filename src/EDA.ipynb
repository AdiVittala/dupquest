{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import persistence as ps\n",
    "from urllib3.response import HTTPResponse\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import partition_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BUCKET = 'dq-data'\n",
    "HASH_BUCKET = 'dq-hashed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train_set\n",
    "data = 'train.csv'\n",
    "filestream = ps.get_file_stream(bucket=INPUT_BUCKET, filename=data)\n",
    "dtypes = {\n",
    "    'id': 'int64',\n",
    "    'qid1': 'int64',\n",
    "    'qid2': 'int64',\n",
    "    'question1': 'object',\n",
    "    'question2': 'object',\n",
    "    'is_duplicate': 'int64'\n",
    "}\n",
    "df = pd.read_csv(#urlpath=s3_in_url, \n",
    "                                     #storage_options=s3_options,\n",
    "                                     filestream,\n",
    "                                     header=0, \n",
    "                                     usecols=dtypes.keys(), \n",
    "                                     #names=dtypes.keys(),\n",
    "                                     skipinitialspace=True,\n",
    "                                     skip_blank_lines=True,\n",
    "                                     encoding='utf-8')\n",
    "df = df.set_index('id')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 404287 entries, 0 to 404289\n",
      "Data columns (total 5 columns):\n",
      "qid1            404287 non-null int64\n",
      "qid2            404287 non-null int64\n",
      "question1       404287 non-null object\n",
      "question2       404287 non-null object\n",
      "is_duplicate    404287 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#shrink df to 150,000 records\n",
    "df = df.iloc[:75000]\n",
    "\n",
    "X = df.drop(columns=['is_duplicate'])\n",
    "\n",
    "y = df['is_duplicate']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50250 entries, 71916 to 15795\n",
      "Data columns (total 4 columns):\n",
      "qid1         50250 non-null int64\n",
      "qid2         50250 non-null int64\n",
      "question1    50250 non-null object\n",
      "question2    50250 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,y,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "def get_tokens(process='train'):\n",
    "    if process=='test':\n",
    "        X = X_test\n",
    "    else:\n",
    "        X = X_train\n",
    "    series = pd.Series(pd.concat([X['question1'], X['question2']]),dtype=str)\n",
    "    series.dropna()\n",
    "    for question in series:\n",
    "        yield preprocess_string(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minio.definitions.Object at 0x7f0866aa0668>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_file(bucket=INPUT_BUCKET, filename='cc.en.300.bin.gz', filepath='/tmp/cc.en.300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('/tmp/cc.en.300.bin.gz', 'rb') as f_in:\n",
    "    with open('/tmp/cc.en.300.bin', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.remove('/tmp/cc.en.300.bin.gz')\n",
    "from gensim.models import FastText\n",
    "model = FastText.load_fasttext_format('/tmp/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft_vectors(model, process):\n",
    "    for tokens in get_tokens(process):\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                vector = model.wv[token]\n",
    "            except:\n",
    "                continue\n",
    "            vectors.append(vector)\n",
    "        yield np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100500,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ft = np.array([vectors for vectors in get_ft_vectors(model,'train')])\n",
    "X_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1_ft = X_ft[:len(X_train)]\n",
    "X2_ft = X_ft[len(X_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.concat([X_train, pd.Series(X1_ft, name='q1_ft',index=X_train.index), pd.Series(X2_ft, name='q2_ft',index=X_train.index)], axis=1)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft_test = np.array([vectors for vectors in get_ft_vectors(model,'test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49500,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ft_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1_ft_test = X_ft_test[:len(X_test)]\n",
    "X2_ft_test = X_ft_test[len(X_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_ft_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, polynomial_kernel, sigmoid_kernel, laplacian_kernel, rbf_kernel\n",
    "from scipy.spatial.distance import cdist\n",
    "def compute_pairwise_kernel(pc1, pc2, method='linear'):\n",
    "    if method=='polynomial':\n",
    "        return polynomial_kernel(pc1, pc2, 2)\n",
    "    elif method=='rbf':\n",
    "        return rbf_kernel(pc1, pc2)\n",
    "    elif method=='sigmoid':\n",
    "        return sigmoid_kernel(pc1, pc2)\n",
    "    elif method=='laplacian':\n",
    "        return laplacian_kernel(pc1, pc2)\n",
    "    else:\n",
    "        return linear_kernel(pc1, pc2)\n",
    "    \n",
    "def compute_pairwise_dist(pc1, pc2, method='euclidean'):\n",
    "    if pc1.size == 0:\n",
    "        return []\n",
    "    if pc2.size == 0:\n",
    "        return []\n",
    "    return cdist(pc1, pc2, metric=method)\n",
    "        \n",
    "def assign_pwmetric(df, method='euclidean'):\n",
    "    #return compute_pairwise_kernel(pc1_embd, pc2_embd, method=method)\n",
    "    return df.apply(compute_pairwise_dist, method, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_lengths(X):\n",
    "    q_meta = []\n",
    "    for q in X:\n",
    "        q_meta.append(len(q))\n",
    "    return q_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50250,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_arrays(X):\n",
    "    for y in (x for x in X if x.size>0):\n",
    "        yield np.vsplit(y,len(y))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_meta = get_q_lengths(X1_ft) + get_q_lengths(X2_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((np.concatenate([x for x in split_arrays(X1_ft)]), np.concatenate([x for x in split_arrays(X2_ft)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100367, 300)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X1_ft, X2_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X', 120440512),\n",
       " ('X_test', 59344912),\n",
       " ('X_train', 13036526),\n",
       " ('q_meta', 804064),\n",
       " ('y_train', 804024),\n",
       " ('mahalanobis', 406496),\n",
       " ('X1_rd', 402096),\n",
       " ('X2_rd', 402096),\n",
       " ('braycurtis', 402048),\n",
       " ('canberra', 402048),\n",
       " ('chebyshev', 402048),\n",
       " ('correlation', 402048),\n",
       " ('cosine', 402048),\n",
       " ('dice', 402048),\n",
       " ('hamming', 402048),\n",
       " ('jaccard', 402048),\n",
       " ('kulsinski', 402048),\n",
       " ('rogerstanimoto', 402048),\n",
       " ('russellrao', 402048),\n",
       " ('sokalmichener', 402048),\n",
       " ('yule', 402048),\n",
       " ('q_meta_test', 396064),\n",
       " ('y_test', 396024),\n",
       " ('Client', 3096),\n",
       " ('FastText', 2000),\n",
       " ('HTTPResponse', 1464),\n",
       " ('Geometry', 1056),\n",
       " ('Dict', 888),\n",
       " ('List', 888),\n",
       " ('Tuple', 888),\n",
       " ('y', 816),\n",
       " ('dtypes', 368),\n",
       " ('f_out', 176),\n",
       " ('assign_pwmetric', 136),\n",
       " ('cdist', 136),\n",
       " ('compute', 136),\n",
       " ('compute_pairwise_dist', 136),\n",
       " ('compute_pairwise_kernel', 136),\n",
       " ('get_ft_vectors', 136),\n",
       " ('get_q_lengths', 136),\n",
       " ('get_tokens', 136),\n",
       " ('laplacian_kernel', 136),\n",
       " ('linear_kernel', 136),\n",
       " ('mmread', 136),\n",
       " ('mmwrite', 136),\n",
       " ('partition_all', 136),\n",
       " ('polynomial_kernel', 136),\n",
       " ('preprocess_string', 136),\n",
       " ('rbf_kernel', 136),\n",
       " ('sigmoid_kernel', 136),\n",
       " ('split_arrays', 136),\n",
       " ('train_test_split', 136),\n",
       " ('q1', 112),\n",
       " ('q1_rd', 112),\n",
       " ('q2', 112),\n",
       " ('q2_rd', 112),\n",
       " ('X1_ft_test', 96),\n",
       " ('X1_rd_test', 96),\n",
       " ('X2_ft_test', 96),\n",
       " ('X2_rd_test', 96),\n",
       " ('dd', 80),\n",
       " ('np', 80),\n",
       " ('pd', 80),\n",
       " ('ps', 80),\n",
       " ('q_tuple', 64),\n",
       " ('HASH_BUCKET', 58),\n",
       " ('data', 58),\n",
       " ('INPUT_BUCKET', 56),\n",
       " ('client', 56),\n",
       " ('delayed', 56),\n",
       " ('f_in', 56),\n",
       " ('filestream', 56),\n",
       " ('braycurtis_test', 48),\n",
       " ('canberra_test', 48),\n",
       " ('chebyshev_test', 48),\n",
       " ('correlation_test', 48),\n",
       " ('cosine_test', 48),\n",
       " ('dice_test', 48),\n",
       " ('hamming_test', 48),\n",
       " ('jaccard_test', 48),\n",
       " ('kulsinski_test', 48),\n",
       " ('rogerstanimoto_test', 48),\n",
       " ('russellrao_test', 48),\n",
       " ('sokalmichener_test', 48),\n",
       " ('yule_test', 48),\n",
       " ('X_rd_halflen', 28),\n",
       " ('len_q1', 28),\n",
       " ('len_q2', 28),\n",
       " ('q_halflen', 28),\n",
       " ('X1_len', 24)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) \n",
    "        for x in dir() if not x.startswith('_') \n",
    "        and x not in sys.modules and x not in ipython_vars], \n",
    "       key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmwrite, mmread\n",
    "mmwrite( 'wor2vec_300_train.mtx', X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushed file wor2vec_300_train.mtx from wor2vec_300_train.mtx to minio bucket dq-data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.copy_file(dest_bucket=INPUT_BUCKET, file='wor2vec_300_train.mtx', source='wor2vec_300_train.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minio.definitions.Object at 0x7f07f6394e10>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_file(bucket=INPUT_BUCKET, filename='embed_train.mtx', filepath='embed_train.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "X_rd = mmread('embed_train.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100367, 3)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100500"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild X1_rd and X2_rd\n",
    "X1_list = []\n",
    "X2_list = []\n",
    "q_halflen = int(len(q_meta)/2)\n",
    "q1_meta = q_meta[:q_halflen]\n",
    "q2_meta = q_meta[q_halflen:]\n",
    "X_rd_halflen = int(X_rd.shape[0]/2)\n",
    "X1_rd_tmp = X_rd[:X_rd_halflen]\n",
    "X2_rd_tmp = X_rd[X_rd_halflen:]\n",
    "for len_q1, len_q2 in zip(q1_meta, q2_meta):\n",
    "    q1 = X1_rd_tmp[:len_q1]\n",
    "    q2 = X2_rd_tmp[:len_q2]\n",
    "    X1_list.append(q1)\n",
    "    X2_list.append(q2)\n",
    "    X1_rd_tmp = X1_rd_tmp[len_q1:]\n",
    "    X2_rd_tmp = X2_rd_tmp[len_q2:]\n",
    "X1_rd = np.array(X1_list)\n",
    "X2_rd = np.array(X2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X1_list, X2_list, q1_meta, q2_meta, X_rd, X1_rd_tmp, X2_rd_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import delayed, compute\n",
    "from dask.distributed import Client\n",
    "from utils import dask\n",
    "client = dask.create_dask_client(num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = []\n",
    "chebyshev = []\n",
    "braycurtis = []\n",
    "cosine = []\n",
    "correlation = []\n",
    "hamming = []\n",
    "canberra = []\n",
    "#mahalanobis = []\n",
    "yule = []\n",
    "dice = []\n",
    "kulsinski = []\n",
    "rogerstanimoto = []\n",
    "russellrao = []\n",
    "sokalmichener = []\n",
    "for q_tuple in zip(X1_rd, X2_rd):\n",
    "    if q_tuple:\n",
    "        q1_rd, q2_rd = q_tuple\n",
    "        jaccard.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'jaccard'))\n",
    "        chebyshev.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'chebyshev'))\n",
    "        braycurtis.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'braycurtis'))\n",
    "        cosine.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'cosine'))\n",
    "        correlation.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'correlation'))\n",
    "        hamming.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'hamming'))\n",
    "        canberra.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'canberra'))\n",
    "        #mahalanobis.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mahalanobis'))\n",
    "        yule.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'yule'))\n",
    "        dice.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'dice'))\n",
    "        kulsinski.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'kulsinski'))\n",
    "        rogerstanimoto.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'rogerstanimoto'))\n",
    "        russellrao.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'russellrao'))\n",
    "        sokalmichener.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'sokalmichener'))\n",
    "    else:\n",
    "        jaccard.append(delayed([]))\n",
    "        chebyshev.append(delayed([]))\n",
    "        braycurtis.append(delayed([])) \n",
    "        cosine.append(delayed([]))\n",
    "        correlation.append(delayed([]))\n",
    "        hamming.append(delayed([])) \n",
    "        canberra.append(delayed([]))\n",
    "        #mahalanobis.append(delayed([]))\n",
    "        yule.append(delayed([])) \n",
    "        dice.append(delayed([]))\n",
    "        kulsinski.append(delayed([]))\n",
    "        rogerstanimoto.append(delayed([])) \n",
    "        russellrao.append(delayed([]))\n",
    "        sokalmichener.append(delayed([])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = compute(*jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev = compute(*chebyshev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "braycurtis = compute(*braycurtis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = compute(*cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = compute(*correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming = compute(*hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "canberra = compute(*canberra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "yule = compute(*yule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = compute(*dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "kulsinski = compute(*kulsinski)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rogerstanimoto = compute(*rogerstanimoto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "russellrao = compute(*russellrao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "sokalmichener = compute(*sokalmichener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50250"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(braycurtis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add above metrics to X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>chebyshev</th>\n",
       "      <th>braycurtis</th>\n",
       "      <th>cosine</th>\n",
       "      <th>correlation</th>\n",
       "      <th>hamming</th>\n",
       "      <th>canberra</th>\n",
       "      <th>yule</th>\n",
       "      <th>dice</th>\n",
       "      <th>kulsinski</th>\n",
       "      <th>rogerstanimoto</th>\n",
       "      <th>russellrao</th>\n",
       "      <th>sokalmichener</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71916</th>\n",
       "      <td>123674</td>\n",
       "      <td>123675</td>\n",
       "      <td>What are the uses nitrous oxide?</td>\n",
       "      <td>When is nitrous oxide used?</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]</td>\n",
       "      <td>[[0.014126931602426835, 0.012581112662755235],...</td>\n",
       "      <td>[[7.192769595735011, 1.0508811404370453], [3.3...</td>\n",
       "      <td>[[1.9928794846028173, 0.9876017385688001], [2....</td>\n",
       "      <td>[[1.9990646340809, 0.8290676419744057], [1.961...</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]</td>\n",
       "      <td>[[3.0, 2.374214601134712], [0.0004180739245818...</td>\n",
       "      <td>[[nan, nan], [nan, nan], [nan, nan]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43137</th>\n",
       "      <td>77630</td>\n",
       "      <td>77631</td>\n",
       "      <td>Why is everyone craving for my attention?</td>\n",
       "      <td>Why do I crave attention?</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0]]</td>\n",
       "      <td>[[0.0025916664134411427, 0.003734074629871132]...</td>\n",
       "      <td>[[0.8056192916790164, 0.8820333320079468], [0....</td>\n",
       "      <td>[[0.4904439764915841, 0.9601788570284864], [0....</td>\n",
       "      <td>[[0.5529982013627186, 0.19406683678255077], [0...</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0]]</td>\n",
       "      <td>[[1.9797973210198996, 2.2020987126465954], [1....</td>\n",
       "      <td>[[nan, nan], [nan, nan]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0]]</td>\n",
       "      <td>[[0.0, 0.0], [0.0, 0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66647</th>\n",
       "      <td>115486</td>\n",
       "      <td>115487</td>\n",
       "      <td>Amazing facts about female body?</td>\n",
       "      <td>Is Fantasy cricket leauge is legit and safe in...</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[[0.013495506135781002, 0.008361488983873884, ...</td>\n",
       "      <td>[[1.7389287628370538, 3.082026603286921, 1.122...</td>\n",
       "      <td>[[1.706409657188209, 1.8502682602333516, 1.187...</td>\n",
       "      <td>[[1.3143016943547168, 1.7405977529289918, 1.73...</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[[2.791127304823243, 2.1952025342832835, 2.464...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21351</th>\n",
       "      <td>40208</td>\n",
       "      <td>24198</td>\n",
       "      <td>Why did not government changed 1000 rupees not...</td>\n",
       "      <td>Why did RBI choose to come out with a ₹2000 no...</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1....</td>\n",
       "      <td>[[0.006135665268631926, 0.0022207229085029864,...</td>\n",
       "      <td>[[0.8118536465828418, 0.758105060833011, 0.238...</td>\n",
       "      <td>[[0.8179461458545746, 0.908097707647699, 0.007...</td>\n",
       "      <td>[[0.8191842962784616, 0.8942658152743844, 4.90...</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1....</td>\n",
       "      <td>[[1.8498885147898858, 2.0753995912271237, 0.82...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan], [nan, na...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68289</th>\n",
       "      <td>118038</td>\n",
       "      <td>118039</td>\n",
       "      <td>What are ideas for Mexican themed party food?</td>\n",
       "      <td>Where can I find Mexican food in mainland China?</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [...</td>\n",
       "      <td>[[0.0027977673856161055, 0.005010864998591739,...</td>\n",
       "      <td>[[1.0450967041196748, 2.1282196707603966, 0.77...</td>\n",
       "      <td>[[1.1759060353880262, 1.721726227280588, 0.951...</td>\n",
       "      <td>[[1.1268274287351194, 0.9627227139611261, 0.74...</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [...</td>\n",
       "      <td>[[2.257326933695591, 3.0, 2.0013512893087393, ...</td>\n",
       "      <td>[[nan, nan, nan, nan], [nan, nan, nan, nan], [...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid1    qid2                                          question1  \\\n",
       "id                                                                         \n",
       "71916  123674  123675                   What are the uses nitrous oxide?   \n",
       "43137   77630   77631          Why is everyone craving for my attention?   \n",
       "66647  115486  115487                   Amazing facts about female body?   \n",
       "21351   40208   24198  Why did not government changed 1000 rupees not...   \n",
       "68289  118038  118039      What are ideas for Mexican themed party food?   \n",
       "\n",
       "                                               question2  \\\n",
       "id                                                         \n",
       "71916                        When is nitrous oxide used?   \n",
       "43137                          Why do I crave attention?   \n",
       "66647  Is Fantasy cricket leauge is legit and safe in...   \n",
       "21351  Why did RBI choose to come out with a ₹2000 no...   \n",
       "68289   Where can I find Mexican food in mainland China?   \n",
       "\n",
       "                                                 jaccard  \\\n",
       "id                                                         \n",
       "71916               [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]   \n",
       "43137                           [[1.0, 1.0], [1.0, 1.0]]   \n",
       "66647  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "21351  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1....   \n",
       "68289  [[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [...   \n",
       "\n",
       "                                               chebyshev  \\\n",
       "id                                                         \n",
       "71916  [[0.014126931602426835, 0.012581112662755235],...   \n",
       "43137  [[0.0025916664134411427, 0.003734074629871132]...   \n",
       "66647  [[0.013495506135781002, 0.008361488983873884, ...   \n",
       "21351  [[0.006135665268631926, 0.0022207229085029864,...   \n",
       "68289  [[0.0027977673856161055, 0.005010864998591739,...   \n",
       "\n",
       "                                              braycurtis  \\\n",
       "id                                                         \n",
       "71916  [[7.192769595735011, 1.0508811404370453], [3.3...   \n",
       "43137  [[0.8056192916790164, 0.8820333320079468], [0....   \n",
       "66647  [[1.7389287628370538, 3.082026603286921, 1.122...   \n",
       "21351  [[0.8118536465828418, 0.758105060833011, 0.238...   \n",
       "68289  [[1.0450967041196748, 2.1282196707603966, 0.77...   \n",
       "\n",
       "                                                  cosine  \\\n",
       "id                                                         \n",
       "71916  [[1.9928794846028173, 0.9876017385688001], [2....   \n",
       "43137  [[0.4904439764915841, 0.9601788570284864], [0....   \n",
       "66647  [[1.706409657188209, 1.8502682602333516, 1.187...   \n",
       "21351  [[0.8179461458545746, 0.908097707647699, 0.007...   \n",
       "68289  [[1.1759060353880262, 1.721726227280588, 0.951...   \n",
       "\n",
       "                                             correlation  \\\n",
       "id                                                         \n",
       "71916  [[1.9990646340809, 0.8290676419744057], [1.961...   \n",
       "43137  [[0.5529982013627186, 0.19406683678255077], [0...   \n",
       "66647  [[1.3143016943547168, 1.7405977529289918, 1.73...   \n",
       "21351  [[0.8191842962784616, 0.8942658152743844, 4.90...   \n",
       "68289  [[1.1268274287351194, 0.9627227139611261, 0.74...   \n",
       "\n",
       "                                                 hamming  \\\n",
       "id                                                         \n",
       "71916               [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]   \n",
       "43137                           [[1.0, 1.0], [1.0, 1.0]]   \n",
       "66647  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "21351  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1....   \n",
       "68289  [[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0], [...   \n",
       "\n",
       "                                                canberra  \\\n",
       "id                                                         \n",
       "71916  [[3.0, 2.374214601134712], [0.0004180739245818...   \n",
       "43137  [[1.9797973210198996, 2.2020987126465954], [1....   \n",
       "66647  [[2.791127304823243, 2.1952025342832835, 2.464...   \n",
       "21351  [[1.8498885147898858, 2.0753995912271237, 0.82...   \n",
       "68289  [[2.257326933695591, 3.0, 2.0013512893087393, ...   \n",
       "\n",
       "                                                    yule  \\\n",
       "id                                                         \n",
       "71916               [[nan, nan], [nan, nan], [nan, nan]]   \n",
       "43137                           [[nan, nan], [nan, nan]]   \n",
       "66647  [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...   \n",
       "21351  [[nan, nan, nan, nan, nan, nan, nan], [nan, na...   \n",
       "68289  [[nan, nan, nan, nan], [nan, nan, nan, nan], [...   \n",
       "\n",
       "                                                    dice  \\\n",
       "id                                                         \n",
       "71916               [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]   \n",
       "43137                           [[0.0, 0.0], [0.0, 0.0]]   \n",
       "66647  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "21351  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....   \n",
       "68289  [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...   \n",
       "\n",
       "                                               kulsinski  \\\n",
       "id                                                         \n",
       "71916               [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]   \n",
       "43137                           [[0.0, 0.0], [0.0, 0.0]]   \n",
       "66647  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "21351  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....   \n",
       "68289  [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...   \n",
       "\n",
       "                                          rogerstanimoto  \\\n",
       "id                                                         \n",
       "71916               [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]   \n",
       "43137                           [[0.0, 0.0], [0.0, 0.0]]   \n",
       "66647  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "21351  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....   \n",
       "68289  [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...   \n",
       "\n",
       "                                              russellrao  \\\n",
       "id                                                         \n",
       "71916               [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]   \n",
       "43137                           [[0.0, 0.0], [0.0, 0.0]]   \n",
       "66647  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "21351  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....   \n",
       "68289  [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...   \n",
       "\n",
       "                                           sokalmichener  \n",
       "id                                                        \n",
       "71916               [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]  \n",
       "43137                           [[0.0, 0.0], [0.0, 0.0]]  \n",
       "66647  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "21351  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0....  \n",
       "68289  [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([X_train, \n",
    "                     pd.Series(jaccard, name='jaccard',index=X_train.index), \n",
    "                     pd.Series(chebyshev, name='chebyshev',index=X_train.index), \n",
    "                     pd.Series(braycurtis, name='braycurtis',index=X_train.index), \n",
    "                     pd.Series(cosine, name='cosine',index=X_train.index), \n",
    "                     pd.Series(correlation, name='correlation',index=X_train.index), \n",
    "                     pd.Series(hamming, name='hamming',index=X_train.index), \n",
    "                     pd.Series(canberra, name='canberra',index=X_train.index), \n",
    "                     pd.Series(yule, name='yule',index=X_train.index), \n",
    "                     pd.Series(dice, name='dice',index=X_train.index), \n",
    "                     pd.Series(kulsinski, name='kulsinski',index=X_train.index), \n",
    "                     pd.Series(rogerstanimoto, name='rogerstanimoto',index=X_train.index), \n",
    "                     pd.Series(russellrao, name='russellrao',index=X_train.index), \n",
    "                     pd.Series(sokalmichener, name='sokalmichener',index=X_train.index)\n",
    "                    ], axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_meta_test = get_q_lengths(X1_ft_test) + get_q_lengths(X2_ft_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack((np.concatenate([x for x in split_arrays(X1_ft_test)]), np.concatenate([x for x in split_arrays(X2_ft_test)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmwrite, mmread\n",
    "mmwrite( 'wor2vec_300_test.mtx', X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushed file wor2vec_300_test.mtx from wor2vec_300_test.mtx to minio bucket dq-data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.copy_file(dest_bucket=INPUT_BUCKET, file='wor2vec_300_test.mtx', source='wor2vec_300_test.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minio.definitions.Object at 0x7f07d54e6978>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_file(bucket=INPUT_BUCKET, filename='embed_test.mtx', filepath='embed_test.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import mmread\n",
    "X_rd_test = mmread('embed_test.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49454, 3)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild X1_rd and X2_rd\n",
    "X1_list = []\n",
    "X2_list = []\n",
    "q_halflen = int(len(q_meta_test)/2)\n",
    "q1_meta = q_meta_test[:q_halflen]\n",
    "q2_meta = q_meta_test[q_halflen:]\n",
    "X_rd_halflen = int(X_rd_test.shape[0]/2)\n",
    "X1_rd_tmp = X_rd_test[:X_rd_halflen]\n",
    "X2_rd_tmp = X_rd_test[X_rd_halflen:]\n",
    "for len_q1, len_q2 in zip(q1_meta, q2_meta):\n",
    "    q1 = X1_rd_tmp[:len_q1]\n",
    "    q2 = X2_rd_tmp[:len_q2]\n",
    "    X1_list.append(q1)\n",
    "    X2_list.append(q2)\n",
    "    X1_rd_tmp = X1_rd_tmp[len_q1:]\n",
    "    X2_rd_tmp = X2_rd_tmp[len_q2:]\n",
    "X1_rd_test = np.array(X1_list)\n",
    "X2_rd_test = np.array(X2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24750,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_rd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X1_list, X2_list, q1_meta, q2_meta, X_rd_test, X1_rd_tmp, X2_rd_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "jaccard_test = []\n",
    "chebyshev_test = []\n",
    "braycurtis_test = []\n",
    "cosine_test = []\n",
    "correlation_test = []\n",
    "hamming_test = []\n",
    "canberra_test = []\n",
    "#mahalanobis_test = []\n",
    "yule_test = []\n",
    "dice_test = []\n",
    "kulsinski_test = []\n",
    "rogerstanimoto_test = []\n",
    "russellrao_test = []\n",
    "sokalmichener_test = []\n",
    "for q_tuple in zip(X1_rd_test, X2_rd_test):\n",
    "    if q_tuple:\n",
    "        q1_rd, q2_rd = q_tuple\n",
    "        jaccard_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'jaccard'))\n",
    "        chebyshev_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'chebyshev'))\n",
    "        braycurtis_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'braycurtis'))\n",
    "        cosine_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'cosine'))\n",
    "        correlation_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'correlation'))\n",
    "        hamming_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'hamming'))\n",
    "        canberra_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'canberra'))\n",
    "        #mahalanobis_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'mahalanobis'))\n",
    "        yule_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'yule'))\n",
    "        dice_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'dice'))\n",
    "        kulsinski_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'kulsinski'))\n",
    "        rogerstanimoto_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'rogerstanimoto'))\n",
    "        russellrao_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'russellrao'))\n",
    "        sokalmichener_test.append(delayed(compute_pairwise_dist)(q1_rd, q2_rd, 'sokalmichener'))\n",
    "    else:\n",
    "        jaccard_test.append(delayed([]))\n",
    "        chebyshev_test.append(delayed([]))\n",
    "        braycurtis_test.append(delayed([])) \n",
    "        cosine_test.append(delayed([]))\n",
    "        correlation_test.append(delayed([]))\n",
    "        hamming_test.append(delayed([])) \n",
    "        canberra_test.append(delayed([]))\n",
    "        #mahalanobis_test.append(delayed([]))\n",
    "        yule_test.append(delayed([])) \n",
    "        dice_test.append(delayed([]))\n",
    "        kulsinski_test.append(delayed([]))\n",
    "        rogerstanimoto_test.append(delayed([])) \n",
    "        russellrao_test.append(delayed([]))\n",
    "        sokalmichener_test.append(delayed([])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "jaccard_test = compute(*jaccard_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "chebyshev_test = compute(*chebyshev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "braycurtis_test = compute(*braycurtis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "cosine_test = compute(*cosine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "correlation_test = compute(*correlation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 21% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "hamming_test = compute(*hamming_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "canberra_test = compute(*canberra_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mahalanobis_test = compute(*mahalanobis_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "yule_test = compute(*yule_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "dice_test = compute(*dice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "kulsinski_test = compute(*kulsinski_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "rogerstanimoto_test = compute(*rogerstanimoto_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 24% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "russellrao_test = compute(*russellrao_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 23% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "sokalmichener_test = compute(*sokalmichener_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-25d73e57fc25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m X_test = pd.concat([X_test, \n\u001b[0;32m----> 2\u001b[0;31m                      \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jaccard'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                      \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchebyshev_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'chebyshev'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbraycurtis_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'braycurtis'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "X_test = pd.concat([X_test, \n",
    "                     pd.Series(jaccard_test, name='jaccard',index=X_test.index), \n",
    "                     pd.Series(chebyshev_test, name='chebyshev',index=X_test.index), \n",
    "                     pd.Series(braycurtis_test, name='braycurtis',index=X_test.index), \n",
    "                     pd.Series(cosine_test, name='cosine',index=X_test.index), \n",
    "                     pd.Series(correlation_test, name='correlation',index=X_test.index), \n",
    "                     pd.Series(hamming_test, name='hamming',index=X_test.index), \n",
    "                     pd.Series(canberra_test, name='canberra',index=X_test.index), \n",
    "                     pd.Series(yule_test, name='yule',index=X_test.index), \n",
    "                     pd.Series(dice_test, name='dice',index=X_test.index), \n",
    "                     pd.Series(kulsinski_test, name='kulsinski',index=X_test.index), \n",
    "                     pd.Series(rogerstanimoto_test, name='rogerstanimoto',index=X_test.index), \n",
    "                     pd.Series(russellrao_test, name='russellrao',index=X_test.index), \n",
    "                     pd.Series(sokalmichener_test, name='sokalmichener',index=X_test.index)\n",
    "                    ], axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pass_through = lambda x:x\n",
    "tfidf = TfidfVectorizer(analyzer=pass_through)\n",
    "X_trfmd = tfidf.fit_transform(get_tokens('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trfmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction using SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import time\n",
    "start = time.time()\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "X_svd = svd.fit_transform(X_trfmd)\n",
    "end =  time.time()\n",
    "print('created SVD transform in time {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1 = X_svd[:len(X_train), :]\n",
    "X2 = X_svd[len(X_train):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_trfmd = tfidf.transform(get_tokens('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_trfmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension reduction using SVD\n",
    "start = time.time()\n",
    "X_test_svd = svd.transform(X_test_trfmd)\n",
    "end =  time.time()\n",
    "print('created SVD transform in time {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back into two\n",
    "X1_test = X_test_svd[:len(X_test), :]\n",
    "X2_test = X_test_svd[len(X_test):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build complete feature dataframe\n",
    "X_test_temp = pd.concat([pd.DataFrame(X1_test, columns=['q1_'+str(i) for i in range(X1_test.shape[1])], index=X_test.index), \n",
    "                    pd.DataFrame(X2_test, columns=['q2_'+str(i) for i in range(X2_test.shape[1])], index=X_test.index)], axis=1)\n",
    "X_test_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy-wuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in text size\n",
    "compute_size_diff = lambda row: abs(len(str(row['question1'])) - len(str(row['question2'])))\n",
    "X_train['size_diff'] = X_train.apply(compute_size_diff, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio\n",
    "compute_ratio = lambda row: fuzz.ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['ratio'] = X_train.apply(compute_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial ratio\n",
    "compute_partial_ratio = lambda row: fuzz.partial_ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['partial_ratio'] = X_train.apply(compute_partial_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_sort_ratio\n",
    "compute_token_sort_ratio = lambda row: fuzz.token_sort_ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['token_sort_ratio'] = X_train.apply(compute_token_sort_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_set_ratio\n",
    "compute_token_set_ratio = lambda row: fuzz.token_set_ratio(str(row['question1']), str(row['question2']))\n",
    "X_train['token_set_ratio'] = X_train.apply(compute_token_set_ratio, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build complete feature dataframe\n",
    "X_train_temp = pd.concat([pd.DataFrame(X1, columns=['q1_'+str(i) for i in range(X1.shape[1])], index=X_train.index), \n",
    "                     pd.DataFrame(X2, columns=['q2_'+str(i) for i in range(X2.shape[1])], index=X_train.index)], axis=1)\n",
    "X_train_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_temp, X_train], axis=1)\n",
    "del X_train_temp\n",
    "X_train = X_train.drop(columns=['qid1', 'qid2','question1','question2'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in text size\n",
    "X_test['size_diff'] = X_test.apply(compute_size_diff, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio\n",
    "X_test['ratio'] = X_test.apply(compute_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial ratio\n",
    "X_test['partial_ratio'] = X_test.apply(compute_partial_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_sort_ratio\n",
    "X_test['token_sort_ratio'] = X_test.apply(compute_token_sort_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_set_ratio\n",
    "X_test['token_set_ratio'] = X_test.apply(compute_token_set_ratio, axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test_temp, X_test], axis=1)\n",
    "del X_test_temp\n",
    "X_test = X_test.drop(columns=['question1','question2', 'qid1', 'qid2'])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "logr_model = LogisticRegression(random_state=42)\n",
    "param_grid = {'C': np.logspace(-2, 7, 10),\n",
    "             #'penalty': ['l1','l2'],\n",
    "             'tol': np.logspace(-5, -1, 5),\n",
    "             #'solver': ['lbfgs']\n",
    "             #'max_iter': np.linspace(10, 1000, 10)\n",
    "             }\n",
    "logr_cv = RandomizedSearchCV(logr_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
    "logr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_model = LogisticRegression(#solver=logr_cv.best_params_['solver'], \n",
    "                                random_state=42, \n",
    "                                C=logr_cv.best_params_['C'], \n",
    "                                tol=logr_cv.best_params_['tol'], \n",
    "                                #max_iter=logr_cv.best_params_['max_iter'], \n",
    "                                n_jobs=-1)\n",
    "logr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_pred = logr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "logr_acc_score = accuracy_score(y_test, logr_pred)\n",
    "logr_prec_score = precision_score(y_test, logr_pred)\n",
    "logr_rec_score = recall_score(y_test, logr_pred)\n",
    "print('Logistic Regression')\n",
    "print('accuracy score : {}'.format(logr_acc_score))\n",
    "print('precision score : {}'.format(logr_prec_score))\n",
    "print('recall score : {}'.format(logr_rec_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
